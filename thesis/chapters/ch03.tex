\section{Speech Processing software and tools}
\subsection{TensorFlow}

The paragraphs and subsections that follow under this topic give an overview of the TensorFlow library as outlined by the following authors \cite{goldsborough2016tour,abadi2016tensorflow,abadi2017computational}

TensorFlow is a state-of-the-art high performance library by Google for Deep learning.  Deep learning is a branch of artificial intelligence which acquires learning from deep neural network architectures. Deep learning has significantly advanced in various application domains and by far out-performed traditional approaches.  TensorFlow, offers researchers and enthusiasts an open source software library for use in defining, training and deploying deep learning models.

TensorFlow works by defining dataflow graphs with mutable state.  A dataflow graph consists of nodes and edges, where each node represents an instantiation of an operation, and values flow along the edges. The operations are implemented by kernels that represent abstractions for particular types of interchangeable devices (such as CPUs and GPUs).

There are three main concepts TensorFlow's core.  They are tensors, operations and mutability.  Tensors are arrays of arbitrary dimensions where the underlying data type is either specified or inferred at graph-construction time. Operations process data and constitute nodes within the compute graph. Basic operations invariably are mathematical functions such as vector dot products.  However, some of the operations indeed may be associated with a read or state update. Such tensor which permit run-time updates in TensorFlow are referred to as variables.  Finally, there may be edges for communicating and constrain the order of execution. These structures invariably affect the observable graph semantics and may also affect the computation performance. 

Once a client constructs a graph using a front-end interface such the Python API, the client can send messages to the graph, by “feeding” inputs and “fetching” outputs. TensorFlow then propagates the input values, through the execution graph and performing  operations called by the client code, until all nodes instructed to run returned with their outputs. 

Data dependencies and control edges, dictate the order of execution. Often, a graph is executed severally and tensors declared as placeholders or constants are used once. However, variable tensors have mutable state which allow persistence across multiple executions. The parameters of the model stored in variables variables are usually updated as part of running the graph.

\subsubsection{Programming Model}
In this section examples of execution data flow graphs are given; and in the following sections we highlight the other major special features of TensorFlow including automatic differentiation and back-prop algorithm implementation, control flow, check pointing, programming interface, sample implementation and graph visualisation.

In a TensorFlow computational data flow graph, vertices or nodes of the directed graph represent operations, while edges signify flow of data between these vertices or operations. Thus labels on nodes are representative of the actions taken at that node.  Similarly, labels representing values flow in the direction of the edges. The inputs to a labeled operation are therefore the labels which have edges directed towards the operation. A computation or data flow graph is illustrated in Figure \ref{fig_c3_tfg}. 
\begin{figure}
\centering
  % Requires \usepackage{graphicx}
  \includegraphics[width=9cm]{thesis/images/tfgraph}\\
  \caption{Sample TensorFlow computation graphs\citep{goldsborough2016tour}}\label{fig_c3_tfg}
\end{figure}

The left graph displays a basic compute graph consisting of an addition operator having two input variables $x$ and $y$.  The result, $z$ is the output of the $+$ operation.  The right graph gives an example logistic regression function. $\hat{y}$ is the final output of the function for some sample vector $\mathbf{x}$, weight vector $\mathbf{w}$ and scalar bias $b$.  As shown in the graph, $\hat{y}$ is the output of the sigmoid or logistic function $\sigma$

\subsubsection{Backprop nodes}
If a neural network consists of two hidden layers represented by functions $$f(x;w)=f_x(w)$$ and $$g(x;w)=g_x(w)$$ with internal weights $$w$$, we can express the cost for that example as $$c=(f_x \circ g_x)(w)=f_x(g_x(w))$$.  We would then typically calculate the gradient $$dc/dw$$ of the cost with respect to the weights and use it to update $$w$$.  The backprop algorithm traverses the graph in reverse to compute the cost using the chain rule $$[f_x(g_x(w))]‘=f‘_x(g_x(w))\cdot g‘x(w)$$.

When TensorFlow needs to compute the gradient of a particular node ν with respect to some other tensor α, it traverses the graph in reverse order from ν to α. Each operation o encountered during this traversal represents a function depending on α and is one of the “links” in the chain (ν ◦ . . . ◦ o ◦ . . .)(α) producing the output tensor of the graph. Therefore, TensorFlow adds a gradient node for each such operation o that takes the gradient of the previous link (the outer function) and multiplies it with its own gradient. At the end of the traversal, there will be a node providing a symbolic handle to the overall target derivative dν/dα , which implicitly implements the back-propagation algorithm. It should now be clear that back-propagation in this symbol-to-symbol approach is just another operation, requiring no exceptional handling. Figure 7 shows how a computational graph may look before and after gradient nodes are added. 

\subsubsection{Control flow}
TensorFlow also supports control-flow operations.  For this reason TensorFlow is not a directed acyclic graph (DAG) but can support cyclic structures. If the number of loops required by the computation graph is known at graph construction.  It is easy to maintain a DAG structure simply by unrolling the number of loops specified.  However, this is not always the case.  There are instances in which a variable number of loops is required at runtime.  Hence, the computation graph becomes increasingly complex.  This is particularly the case for back gradient descent and back propagation of errors (see section \ref{sec_c3_tfwf} for a  walk through).  The process of stepping back through a loop in reverse to compute gradients is known as back-propagation through time \citep{al2016theano}.

\subsubsection{Checkpoints}
One can add Save a node to a compute graph, connecting them to variables whose tensors can then be serialized. At another instance one may connect the same variable to a Restore operation. This operation deserializes the stored tensor at another point within the execution graph. This is especially useful over long periods of training to keep track of the model’s variable parameters. These elements form part of distributed TensorFlow's fault tolerance ecosystem.

\subsubsection{Programming Interface}
TensorFlow implementation provides two developer interfaces which include the Python interface and the C++ interface.  While the python interface offers a rich feature set for creation and execution of computation graphs, the C++ interface is primarily a back end implementation with a much more limited API primarily used for executing graphs built with Python and serialised to Google’s protocol buffer.

It is worth noting that unlike PyTorch \citep{ketkar2017introduction}, the Python API handshakes very well with NumPy\citep{numpy} numeric and scientific open source programming library. As such, TensorFlow tensors can be naturally substituted with NumPy ndarrays without any need for type-conversion seen in PyTorch tensors.
\subsubsection{Typical TensorFlow Workflow using MNIST digit handwriting recognition Data set}\label{sec_c3_tfwf}
We train a simple multi-layer perceptron (MLP) with one input and one output layer to classify hand-writtin digits in the MNIST\citep{krizhevsky2012imagenet} dataset.   In this dataset, the examples are small images 28 x 28 pixels depicting handwritten digits from 0 to 9.

Given an example matrix $\mathbf{X}\in\mathbb{R}^{n\times 784}$ containing  images, the learning task then applies an affine transformation $\mathbf{X\cdot W+b}$, where $\mathbf{W}$ is a weight matrix $\in \mathbb{R}^{784 \times 10}$, and a bias vector $\in R^{10}$.  This yields a new matrix $\mathbf{Y}\in \mathbb{R}^{n\times 10}$, containing the scores or logits of our model for each example and each possible digit.  These scores are more or less arbitrary.  To transform the logits to valid probability distribution, giving the likelihood $Pr[x=i]$ that the -th example represents the digit $i$, we make use of a softmax function in the equation below
\begin{equation}
softmax(\mathbf{x})_i=\frac{\exp(\mathbf{x}_i)}{\Sigma_j\exp(\mathbf{x}_j)}\label{eqn_c3_smax00}
\end{equation} 

The objective function is computed to give the error or loss of the model given its current trainable parameters $\mathbf{W}$ and $\mathbf{b}$.  This is obtained by  calculating the  cross entropy     $H(\mathbf{L,Y})_i=−\Sigma_j\mathbf{L}_{i,j}\cdot\log(\mathbf{Y}_{i,j})$
between the probability distributions of our estimates $\mathbf{Y}$ and the one-hot-encoded labels $\mathbf{L}$.  More precisely, the mean cross entropy over all examples as the loss.

Next, the stochastic gradient descent (SGD) is run to update the weights of our model.  A tensorflow class is provided and will be initialised with a learning rate.  The minimise function of this class takes the loss tensor as parameter used for minimisation.

The operations run repeatedly within a tf.Session context manager. Refer to Appendix \ref{app2_01_tfcode} for the complete code listing.

\subsubsection{Visualisation}
TensorFlow interface offers the option of visualising computation graphs. Complex topologies consisting various sub-layers can be presented in a lucid form, offering the user to congruent, organised picture of exactly how data is consumed. Sub-graphs may be grouped into visual blocks and referred to in name scopes.  For example a single neural network layer may take up such a named scope. The name scopes are then interactively expanded on to give the detailed group visualisation.

Two types of metrics are obtainable from the TensorBoard. These are summary operations, when attached as nodes in the graph, permit the user to monitor individual tensor values over time.   The first is the scalar summaries which capture tensor values and can be sampled at certain points within training epochs. One can now, for example, observe the trend of the accuracy loss of the training model over time.

The other summary operation offers the user the ability to track distributions, such as final soft-max densities or the distribution of neural network weights. 

Lastly, sample images can be visualised on the TensorBoard graph. This way kernel filters of a convolutional neural network can also be visualised.  In addition to all of these, one can perform zooming and panning actions directly on TensorBoard's web interface including expansion and collapsing of individual name scopes

\subsection{Choregraphe}
The Choregraphe software tool is a high-level language used for programming of Nao humanoid robots.  This is built on top of the Naoqi/Gentoo Unix/Robot Operating System(ROS) \ref{pot2009choregraphe}.  Speech recognition and processing modules of the Choregraphe tool were explored and expanded at the initial stages of the research.  However the Choregraphe software tool for the Nao robot was found to be unsuitable in speech recognition at the level of research that aligned with the research objectives and therefore was not utilised in this work.

\subsection{Alisa}\label{c3sec_alisa}
Alisa tool is a lightly supervised sentence segmentation tool based on Voice Activity Detection (VAD) algorithms \citep{stan2016alisa}.  It is so called lightly supervised because it requires small amounts of training data.  Generally the tool was asserted to be optimised for sentence segmentation and offered assistance in the creation of new speech corpora in a language-independent fashion. 

The Alisa tool researchers deploy a two-step method for aligning speech, and claim performance up to 70\% imperfect transcriptions often found in online resources can be successfully aligned with a word error rate of less than 0.5\%.  This tool is therefore said to be suitable for development multilingual and under-resourced language aligned speech-corpora.

The motivation behind Alisa was to reduce the time and effort used to gather a large amount of large amounts of quality data as well as actively eliminate the domain knowledge required to phonetically transcribe speech data.  In addition, and as a bonus to achieving the first objective, is the ability to migrate speech technology fairly seamlessly from one language to another and therefore realise the rather tedious task of automatic transcription of a new language.

\subsubsection{Alisa Architecture}
The goal of automatic transcription of new language with low resource constraint is particularly valuable to this research and as such, it would be relevant to review the enhancements introduced to Alisa.  The two step-method consists of a GMM-based sentence level segmenter and also an iterative grapheme acoustic model used for alignment.  The sentence level GMM-based speech segmenter is used to automatically segment speech into utterances which as discussed earlier forms the basic unit of processing within any ASR system.  This attempts to relieve the researcher off the manual process of segmenting the continuous audio file manually. This process included a GMM-based voice activity detector trained from about 10 minutes of manually labeled data. The second step grapheme based acoustic model is supplemented with a highly restricted word network they referred to as a skip network.  Together an iterative acoustic modelling training procedure is formulated.  The method described required the initial training data and a minimal labelling procedure that involved simple letter to sound rules and inter-sentence silence segments to provide an orthographic transcript of the initial 10 minute recording data.  Therefore, this process is resource-effective because non-experts can also provide this data.  The actual alignment process made use of a grapheme level Viterbi decoder to drive the iteratively self-trained grapheme models.  The model architecture is shown in the figure below.
\begin{figure}
\centering
  % Requires \usepackage{graphicx}
  \includegraphics[width=9cm]{thesis/images/alisa}\\
  \caption{Alisa Architecture\citep{stan2016alisa}}\label{fig_c3_alisa00}
\end{figure}

Figure \ref{fig_c3_alisa00} shows a block diagram of the steps involved in the alignment.  The method can be applied to any language with an alphabetic writing system, given the availability of speech resource and its corresponding approximate script.

There is an option of using a grapheme based acoustic model. This however increases the margin for error.  Several steps were introduced in the Alisa tool to minimise this error margin. The chief being the introduction of a tri-grapheme acoustic model which is modeled after using context dependent triphones in traditional acoustic modelling.  Other techniques deployed to crash the error margin include the use of discriminative training with the Maximum Mutual Information (MMI) criterion \citep{schluter2001model} and methods described in \citep{novotney2009analysis}. It was observed that Alisa provided good alignment but was not fully featured. For instance it had no way of adding insertions and substitutions in the audio data not provided in the transcription.  Finally, Alisa was found to be restricted to only languages that can utilise the English alphabet.

\section{Initial Experiments}
The experiments in the following sections describe initial experiments based on the initial study of a language learning companion before the research was narrowed down to a low resource speech recognition.  These preliminary experiments in addition to a preliminary Language Learning Survey helped to narrow down the Research to the specific speech processing task of Low Resource Automatic Speech Recognition (LR-ASR).

The following sections describe analysis of raw wave-forms using auto-correlation signal processing in Matlab and experiments made with the Nao robot speech processing engine and experiments with speech recognition toolkit and speech processing tasks.  These tasks include digit recognition systems using CMUSphinx and Kaldi speech recognition toolkits and speech alignment tasks using Alisa tool.

\subsection{Auto-correlation Experiments}
Preliminary experiments were carried out on raw speech signals in an attempt to quickly segment individual phonemes based on a basic threshold algorithm.  Further experiments designed an autocorrelation algorithm to attempt to discover a phoneme alphabets in a particular dataset in a semi-supervised fashion.
 
This method had desirable goals when compared with other segmentation techniques outlined in the previous chapter. The chief being the ability to simulate a posterior distribution statistic from auto-correlation estimate.  This presents an unnormalised posterior distribution measurement of every phoneme segments over the entire signal.

The correlation theory is based on the idea that when a signals is superimposed on itself in a time-shifted manner, the convolution over itself is highest when the two signals have zero time lag that is, perfectly overlapped in sync and the better the overlapping the higher the value of the correlation and the lesser the signals are matched they tend to cancel out each other and hence a very low value of the correlation.  The normalised auto-correlation value is obtained in \cite{picone1996fundamentals} from a signal $x(n)$ in the following equation:
\begin{equation}
    \Psi(i)=\frac{\sum_{n=0}^{N-1}x(n)x(n-i)}{\left(\sum_{n=0}^{N-1}x(n)^2\right)\left(\sum_{n=0}^{N-1}x(n-i)^2\right)}\label{c3eq_corr}
\end{equation}
Based on experimental procedure, estimated locations of similar wave-forms representing segmented phonemes are calculated.  Although the procedure is subject to degrade in the face of most of the difficulties associated with dealing with raw audio waveform, it further emphasises the need for accurate speech features and pre-processing highlighted in the previous chapter.

This two stage procedure performs segmentation of phonemes and then discovery of phoneme clusters using a statistical auto-correlation algorithm.  The process is described in the following sections.
\begin{figure}
\centering
  % Requires \usepackage{graphicx}
  \includegraphics[width=9cm]{thesis/images/corr}\\
  \caption{Original waveform input for auto-correlation}\label{fig_c3_exp01}
\end{figure}

\subsubsection{Segmentation}
Figure \ref{fig_c3_exp02} describes the various steps of the segmentation phase while Figure \ref{fig_c3_exp01} shows the original audio file. At the segmentation phase, we first of all adjust the scale of the original raw audio file to have only positive values rather than having it centred on zero (Figure \ref{fig_c3_exp02}a).  At the next step a smoothing filter based on experimentation is used to perform both smoothing as well as determining the peaks and trough (Figure \ref{fig_c3_exp02}b).  Then a threshold is applied to segment the waveform based on discovered inflection points (Figure \ref{fig_c3_exp02}c).  
\begin{figure}
\centering
  % Requires \usepackage{graphicx}
  \includegraphics[width=9cm]{thesis/images/corr00}\\
  \caption{Original waveform input for auto-correlation}\label{fig_c3_exp02}
\end{figure}
\subsubsection{Auto-correlation}
At the auto-correlation stage estimated phoneme segment boundaries are stored in an array and cross-correlated with the original signal.  Even though at a top-level view, the entire signal is auto-correlated, at the individual segment level, the signals are cross correlated against one another.  Furthermore, to achieve a ‘fair’ correlation estimate, individual segments representing estimated phonemes need to be re-sampled to eliminate mismatching of contour representations of the individual phonemes.

The proposed auto-correlation algorithm performs both top-down and bottom-top processing.  In the first stage it does bottom-top segmentation, while in the second phase top-bottom auto-correlation.   The major weakness is this auto-correlation method the segmentation algorithm, data filtering and the feature representation.  The Bayesian method of segmentation \citep{kamper2016unsupervised} which is related to this method also improved on these weaknesses was able to improve on these weakness by using ASR feature preprocessing and a combination of acoustic embedding Dynamic Time Warping (DTW) for clustering rather than auto-correlation.  In effect using the extracted features for clustering is in theory a better speech estimate with less intrinsic noise for classification than using an only smoothed audio data.

\subsection{Experiments with Nao robot}
Nao is a humanoid robot developed mainly for deployment in environments for robotics education and development purposes.  Nao comes with a speech recognition software that offers features such as language settings and recognition sensitivity.  However it was understandably found to be limited because the Nao robot itself does not possess the processing power to perform CPU intensive training of acoustic models.  The now robot did however offer a level of support for using the pocketsphinx system. The pocketsphinx system is the C-language equivalent of CMUSphinx speech recognizer system also by Carnegie Mellon University.  Using the pocketsphinx method, acoustic models trained high performance systems can then be deployed to Nao for fast decoding within the Nao.  

\subsection{Digit Speech Recognition and Alignment Experiments}\label{sec_digitspeech}
These experiments were performed using CMU Sphinx4 recognition system and Kaldi speech recognition software.  While CMU Sphinx and pocketsphinx delivered standard interface for speech recognition using generative hybrid models, Kaldi speech in addition also offered advanced methods such as subspace Gaussian mixture model used to develop cross-lingual acoustic models and deep architectures for hybrid generative-discriminative models for speech recognition.   The main challenge with Kaldi was that it was CPU intensive and required a reasonable amount of parallel processing to achieve good results within a reasonable time period. 

Speech alignment experiments were performed using the Alisa \cite{stan2016alisa} tool which is a python based tool with calls made to the HMM toolkit \cite{young2002htk}.  The Alisa tool alignment process undergoes a semi-supervised process and requires an error prone time-intensive manual pre-alignment procedure.  The tool itself was found to be quite unstable and the output results were not very easily reproducible for further tests to be carried out on different data sets.  In addition to the time-intensive pre-alignment procedure made the tool not very useful for this research. Had the tool been more successful, the tool, which utilises Voice Activity Detection (VAD) algorithms, would have been especially useful for sentence segmentation of long sequences of transcribed audio speech.  This tool however still lacked in alignment at either a word-level or sub-word level of alignment required in ASR pipelines.

\section{End-to-end Research Experiments}\label{sec_postalign}
The main challenges of speech recognition using HMM-based toolkits such as Kaldi, is the requirement for aligned speech.  In more recent endeavours, there has been efforts towards automatic alignment of transcribed audio speech recordings through successive Baum-Welch estimation techniques \cite{gales2014speech,ragni2018automatic,ragni2014data}. However, this technique is not particularly compatible with end-to-end goals adopted for this research as it would require preprocessing and successive pre-training of the data set.

The following section describes the post-alignment experiments and in a later Chapter, how these methods deal with the problem of automatic speech alignment in a fashion which was compatible with end-to-end speech processing.  The end-to-end requirements were desirable for low-resource speech recognition as it introduces a simpler speech model design.  The downside however to the end-to-end approach is the dependency on very deep recurrent neural network structures which require large volumes of data for successful training.
\subsection{Tensor flow sequence-to-sequence character-to-diacritically-labelled-character model}\label{sec_c2d}
Experiments performed in this and the next three sections are all based on sequence-to-sequence modelling using recurrent neural networks. While the this and the following section represents precursor experiments around speech recognition tasks, the later two sections represent the final experiments reported in this work.

The character-to-diacritically labelled character model was a sequence-to-sequence diacritically labeled experiment to automatically infer diacritic transcriptions of the Wakirike language given the plain unmarked Wakirike language text as input.  This is a task, when achieved successfully is a sub task towards developing a phonetic dictionary for the Wakirike Language which in turn can be used in HMM speech recognition or equivalent  end-to-end models.  This experiment was a precursor experiment, the results of which were reserved for further study.
\subsection{Sequence-to-sequence Grapheme-to-Phoneme (G2P) model}
This is a follow up experiment to the previous experiment in section \ref{sec_c2d}. This model attempts to automatically generate a phonetic dictionary from graphemes in a text corpus. Grapheme-to-phoneme experiments come in two flavours. The first being a continuation of the previous experiment, that is, using diacritically marked symbols and the second flavour using non-marked graphemes as input.  The experiments we performed used the latter non-marked graphemes as input. As this experiment was also a subtask in HMM speech model building,  the results of these experiments were reserved for further study.

What follows in the next three sections are sequence-to-sequence experiments actively developed in this research and are detailed in chapters (\ref{ch6_wlm,ch6_speech,ch8_future}).  A brief summary of the experiments are highlighted in the following sections (\ref{sec_grulm,sec_be2e,c3sec_espnet}).  Note that these models all utilise TensorFlow deep learning library including the Bi-directional speech model (section \ref{sec_be2e}) which is built on top of Mozilla DeepSpeech with the exception of section \ref{c3sec_espnet} which is based on pytorch; a similar deep learning library (see table \ref{tab_tfstats} for comparison).

\subsection{GRU language model for Wakirike language based on TensorFlow}\label{sec_grulm}
The language model developed in this research is a character-based sequence-to-sequence deep recurrent neural network that maps a sequence of characters to a sequence of words found in the training data set. This model met the objective of reducing the vocabulary size required for language models as well as the text corpus required as inferences could be made over the smaller-fixed character vocabulary rather than orders or magnitude larger word corpus with the possibility of out of vocabulary terms found in the training data.  Though this may occur in the character sequence-model at the inference stage.  It would not normally happen during training.  The neural network model developed is described in Chapters \ref{}, consists of Gated Recurrent Unit (GRU) Recurrent Neural Network (RNN). The GRU is a specialised type of Long Short-Term Memory (LSTM) cell RNN.  The emphasis here is on the ability to model over particularly long sequences of the training data.  In this case, over long character sequences.  Thus, the network is able to learn long term dependencies as would be naturally required to construct grammatically correct sentences.  In essence, the RNN is able to learn grammar rules inherently from the training data.

\subsection{Bi-Directional LSTM-based end-to-end speech model}\label{sec_be2e}
A similar LSTM sequence-to-sequence network based on Baidu Research’s original research design \citep{hannun2014deep} is developed in this research for end-to-end speech recognition.  This model, as its name implies, attempts to establish long term relationships by adding a reinforcing LSTM layer learning information but this time from the opposite direction, hence the bi-directional architecture.  

In addition, the model incorporates the Connectionist Temporal Classifier (CTC) decoder. This enables the model to make run-time inferences on both the character as well as estimate audio wave to character label alignment simultaneously.  This makes this design accommodate end-to-end goals and ultimately simplifies the overall design and completely eliminates the need for either manual or semi-supervised alignments mentioned previously in sections (\ref{sec_alisa,sec_digitspeech,sec_postalign}).

\subsection{ESP-Net Experiments}\label{c3sec_espnet}
The ESP-Net (End-to-end Speech Network) toolkit \citep{watanabe2018espnet}, is a speech processing toolkit that was of interest to this research because it offers end-to-end capabilities not only in Automatic Speech Recognition (ASR) but also in Text-To-Speech (TTS) or speech synthesis and other speech-sequence-processing related tasks.  In addition, the toolkit offered multi-modal training combining both Attention networks \cite{vaswani2017attention} with CTC networks as well as multi-channel feature representation that is, the fusing together of multiple feature representations of data.  Only preliminary experiments were carried out using ESPNet and is discussed in Chapter \ref{ch08furtherstudy} of this work.

\section{Method of evaluation}
System building methodology \citep{nunamaker1990systems} for speech recognition systems requires models to be evaluated against speech recognition Machine Learning metrics.  For language models, perplexity metric was used for evaluation.  Bleu has also been used as a metric for evaluating language models.

Perplexity measures the complexity of a language that the language model is designed to represent \citep{1976jelinekcontinuous}. In practice, the entropy of a language with an N-gram language model $P_N(W)$ is measured from a set of sentences and is defined as
\begin{equation}H=\sum_{\mathbf{W}\in\Omega}P_N(\mathbf{W})
\label{eqn_c2_lm05}
\end{equation}

where $\Omega$ is a set of sentences of the language. The perplexity, which is interpreted as the average word-branching factor, is defined as
\begin{equation}PP(W)=2^H
\label{eqn_c2_lm06}
\end{equation}
where H is the average entropy of the system or the average log probability defined as
\begin{equation}
H=-\frac{1}{N}\sum_{i=1}^N[log_2P(w_1,w_2\dots w_N)]
\label{eqn_c2_lm07}
\end{equation}
For a bi gram model therefore, equation (\ref{eqn_c2_lm07}) becomes
\begin{equation}
PP(W)=2^H=2^{-\frac{1}{N}\sum_{i=1}^N[log_2P(w_1,w_2\dots w_N)]}
\label{eqn_c2_lm08}
\end{equation}
After simplifying we have
\begin{equation}
PP(W)=\sqrt[N]{\prod_{i=1}^N\frac{1}{P(w_i|w_{i-1})}}
\label{eqn_c2_lm09}
\end{equation}


Full speech recognition pipelines are usually evaluated against the Word Error Rate (WER).  WER is computed as follows:
\begin{equation}\label{eqn_2_3_wer}
WER=\frac{I+D+R}{WC}\times 100
\end{equation}
Here $I,D,$ and $R$ are wrong insertions, deletions and replacements respectively and $WC$ is the word count.

Metrics used for low speech recognition in the zero speech challenge \citep{versteegh2015zero} include the ABX metric. Other common speech recognition error metrics following a similar definition as the Word Error Rate (WER) are Character Error Rate (CER), Phoneme Error Rate (PER) and Syllabic Error Rate (SyER) and sentence error rate (SER).

\section{Summary of Methodology}
In this chapter we outline how this research set about to achieve its objectives.  The main claim of this research is that by building a speech model that combines knowledge of end-to-end processing along with state of the art signal processing the overall training complexity and build time for new ASR systems can be improved.  This research aims to deliver this through by the unique combination of a CTC-based deep recurrent bi-directional neural network with high performance feature processing of Deep Scattering Networks (DSNs).

This chapter also reviews the technologies utilised by this research in order to arrive at the research outputs and briefly describes the experiments performed.  Within this space we describe CMUSphinx, Kaldi, Mozilla Deepspeech, Tensorflow, Matlab and Scatnet as major libraries used.   The first two being Hidden Markov Model (HMM)-based libraries and the latter being used either integrally or as part of end-to-end  and signal processing systems used to build Deep Recurrent Neural Network (RNN) models. Finally, we mention metrics for the evaluation of the models built in this work.
