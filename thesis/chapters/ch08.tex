\textcolor{blue}{This research has been inspired by the notion of a \acrfull{llc}. One of the artificial intelligence tasks for \acrshort{llc} is \acrfull{asr}.  This research, therefore, explored the current advancements that have been made in the field of \acrshort{asr} and discovered one of the major challenges in field of \acrshort{asr} is that of new and low resourced languages.  In particular, considering \acrshort{asr} as a machine learning pipeline, this research favours a discriminative approach to \acrshort{asr} over generative approaches.  Although hybrid \acrshort{hmm}-\acrshort{dnn}, which is considered a generative model, does deliver state-of-the art results, the \acrshort{asr} pipeline involves training of different aspects of the \acrshort{asr} pipeline in separate processes.  The end-to-end approach, however, attempts to simplify this by offering a solution that involves training of a single discriminative "end-to-end" model. }

\startblue
As \acrshort{asr} is a machine learning pipeline,  the advancement of Machine Learning has had a direct impact on the development of more efficient speech recognition algorithms and at the same time the advancement of speech recognition helps with the improvement of Machine Learning algorithms, as in general, the methods used in Machine Learning usually are directly transferable to speech processing and vice-versa. This mutual relationship implies that speech recognition is a blossoming research field because there is a tremendous amount of work being done in the Machine Learning community. Particularly in the area of deep learning and neural networks, there is quite a vast array of neural network solutions that have been applied or are yet to be applied to speech recognition. This research examined the effect of using a different set of input features from the state-of-the-art log-mel features. Feeding these scatter transform features into end-to-end ASR DNN with the objective of a comparable fast and efficient speech recognition for new and low resource languages. The major advantage of our system is that in addition to robust end-to-end models coupled with unique front-end scatter transform features and the intrinsic integration of a character-based language model help to train low-resource languages for ASR in a resource efficient manner. 

This Chapter summarises the end-to-end and deep sequential models towards low-resource speech recognition developed by this research. In addition, additional models being developed in the research community which are closely related models are mentioned as areas of further research interest.  These include Generative Adversarial Networks (GANs) and Attention-based models. 

\section{Discussion of Output Research models}

Two well established key aspects of \acrshort{asr} from the \acrshort{asr} formulation in Equation \ref{eqn_2_3_bayes_sr} include an \acrfull{am} and a \acrfull{lm}. The objective of this research was to understand these key aspects \acrshort{asr} systems and develop \acrshort{asr} systems that can be accessible by new and or low resource languages.

The research objectives were met by developing speech models based on a neural network end-to-end approach. End-to-end discriminative neural network speech models have now become a well established method in Automatic Speech Recognition.   The Bi-directional Recurrent neural network (\acrshort{birnn}) end-to-end system, developed in this work, however, is augmented by features derived from a deep scattering network as opposed to the standard Mel Frequency Cepstral Coefficients(MFCC) features used in state of the art acoustic models.  These specialised deep scattering features, consumed by the \acrshort{birnn} model, represent a light-weight convolution network. 

\subsection{Main contribution to knowledge}
This work shows that it is possible to build a speech model from a combination of deep scattering features and a Bi-RNN. There has been no record of deep scattering features being used in end-to-end bi-RNN speech models as far as we are aware.  This thesis therefore demonstrates Deep Scattering features derived from wavelet filter operations on audio data produce viable candidates for end-to-end training of Automatic speech recognition models.

\subsection{Summary of goals Achieved in this work}
\stopblue
\section{Directions for future study}
\subsection{Generative adversarial networks (GAN)}

GANs consists of two Networks working as adversaries to one another.  The first, being a generative network, generates content.  The second network is a discriminative network intended to determine the accuracy of the first generative network.  Hence the generative network is generating output less distinguishable for the discriminator while the discriminator uses output from the generator to improve the ability to discriminate output from the generator with the original source data.

GAN networks can have applications where the generative network consists of a speech synthesis network and the discriminating network is  a speech recogniser.  However successive training of these two networks from a data-resource perspective would require an immense amount of data resources for expected performances. 

\subsection{Attention-based Models}

The objective of attention-based networks highlighted by  \cite{vaswani2017attention} is to reduce sequential computation while attaining hidden representation across arbitrary lengths of sequential input. Mechanisms which have been deployed to achieve this includes a combination of convolutional and recurrent schemes \citep{kaiser2016can,kalchbrenner2016neural, gehring2017convolutional}. \cite{vaswani2017attention} introduces a transduction model known as a Transformer based on self attention network with the ability to compute long term dependencies while eliminating sequence aligned RNN and convolutional architectures.

Self attention is a network that intrinsically reduces the need for intensive resource training.  \cite{vaswani2017attention} reports that state of the art BLEU score of 41.0 having used a small fraction of training resources.  While GANs might not be attractive for low resource speech recognition, they still remain an important tool for verification of the output of other networks.  At the same time self attention networks can help to reduce the resource requirements of GANs when used within the context of a GAN.

As a study to further this thesis, these networks are likely candidates for network training using scatter features as input discriminatory functions.  Attention based networks as a means reduce training resources required, while GANs can be used as a means to generate training data.

\subsection{Model Pre-training}
The major setback this work suffered was from a reasonable time for training.  This work therefore recommends that speech models or indeed artificial intelligence models should be trainable within a maximum of 30 days and shouldn't generally exceed 20 days training.

An area of neural network training optimisation not developed in this report is that of layer-wise greedy pre-training.  In this process, rather than train the deep neural network structure all in one stage, the network layers are successively added and trained layer by layer, one layer at a time \citep{Goodfellow-et-al-2016}.  The intuition behind this is that this makes the layers saturate much faster as the previous layer has already been saturated before the new layer is being added.

This layer-wise pretraining procedure is thought to speed up training, than training when done with the fully connected network and there have been a few different approaches to pretraining in for deep neural network architectures for speech recognition. 

\cite{hendrycks2019using} introduces an advanced pretraining method in which existing models are retrained in a Generative Adversarial Network (GAN) fashion in order to optimise performance and model robustness.  This is an instance where GANs are being deployed in speech recognition.  This method however is not likely going to help improve model training convergence time.

Another method described in \citep{ramachandran2016unsupervised,} uses a knowledge transfer mechanism where hidden layers in an already existing related network is re-trained with new extended layers to complete training in the new domain.  The effectiveness of such a transfer method will be measured of the how the two domains correlate with one another. It therefore, would be logical to conclude that the more the domains correlate the faster the pretraining model is likely to converge faster.

Finally, \cite{wang2019bridging} proposes a Tandem Connectionist Encoding Network (TCEN) for bridging the gap for fine tuning CTC-Transformer networks along with pretraining of Attention-transducers.

As a further study, amongst other techniques, the most viable method for this study is to investigate the knowledge transfer mechanism by approaching the feature engineering problem as a latent space analysis problem.  Given that during the process of mapping acoustic speech sequences to the MFCC reduced the latent space from a high dimension to a low dimension.  It is reasonable therefore to hypothesize that training from hidden layers of an MFCC deep RNN would converge faster than weights initialised through generic means.

\startblue
\section{Conclusion}

The outcome of this research is an \acrshort{asr} system which facilitates fast and efficient speech recognition using the end-to-end speech recognition and deep scattering speech features.  Another advantage of our \acrshort{asr} system was the intrinsic integration of a character-based language model enabling it to satisfy both low-resource challenge criteria of top level word and sentence modelling through the character-based language model and the sub-word and acoustic modelling of input features.

The word error rates obtained by our model with different data sizes and speech corpora was not as good as the features using log-mel features. However, the results were competitive 
 
\stopblue



