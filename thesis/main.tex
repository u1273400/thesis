\documentclass[12pt,twoside]{report}
\usepackage[utf8]{inputenc}
\usepackage{graphicx}
\graphicspath{ {images/} }
\usepackage[a4paper,width=150mm,top=25mm,bottom=25mm,bindingoffset=6mm]{geometry}
\usepackage{wrapfig}
\usepackage{lscape}
\usepackage{rotating}
\usepackage{epstopdf}

% package used by \citep and \citet
\usepackage[sort&compress,comma,authoryear]{natbib}
\usepackage[options ]{algorithm2e}

\usepackage{setspace}
\usepackage{amsmath}
\usepackage{booktabs}
\usepackage{fancyhdr}
\pagestyle{fancy}
\fancyhead{}
\fancyhead[RO,LE]{Deep Scattering and End-to-End Speech Models towards Low Resource Speech Recognition}
\fancyfoot{}
\fancyfoot[LE,RO]{\thepage}
\fancyfoot[LO,CE]{Chapter \thechapter}
\fancyfoot[CO,RE]{I. J. Alamina}
\renewcommand{\headrulewidth}{0.4pt}
\renewcommand{\footrulewidth}{0.4pt}

\title{
    {Deep Scattering and End-to-End Speech Models towards Low Resource Speech Recognition}\\
    {\includegraphics{university.png}\\
A thesis submitted to the University of Huddersfield in partial fulfilment of the requirements for the degree of Doctor of Philosophy    }
}


\author{Iyalla John Alamina}
\date{31 October, 2019}

\begin{document}

\maketitle
\spacing{1.5}

\chapter*{Abstract}
This thesis investigates and acknowledges the various limitations of Deep Neural Network (DNN) techniques when applied to low resource speech recognition.   Various aspects of developing corpora for speech recognition systems are explored.  In particular various recurrent neural network (RNN) techniques were explored to implement end-to-end speech and language models (LM). Gated Recurrent Units (GRU) RNNs were used employed for the language model for a low resourced Wakirike language while bidirectional recurrent neural networks (bi-RNNs) were used to create end-to-end speech recognition model for English language.

Previous systems employed for low resource speech recognition involving deep networks included various knowledge transfer mechanisms including hybrid hidden markov models (HMM) to deep neural networks (HMM-DNN) models and those that are HMM alone-based include subspace Gaussian Mixture Models (GMMs).   These models are based on the HMM generative model and N-gram language models.  However, the model developed in this thesis makes use of an end-to-end discriminative model using the Bi-RNN acoustic/speech model augmented using speech features from a specialised light weight convolution network-the deep scattering network (DSN).  While the light weight DSN helped to reduce the training complexity, at the same time by focusing on end-to-end with Connectionist Temporal Classification (CTC) decoding, the speech model was compressed into a one step process rather than a three-step process requiring an AM, LM and phonetic dictionary. The research therefore shows it is possible build speech recognition systems using this compact strategy, while, improving on speech features required for accurate speech pattern recognition by deploying deep scattering network features because they possess higher dimension as opposed to traditional speech features. 

\chapter*{Dedication}
To the praise and glory of our God and of His Christ.

\chapter*{Acknowledgement}
I thank my supervisory team headed by Dr David Wilson for the invaluable guidance and keen interest throughout my research.  

I also acknowledge my parents (Prof. Mrs. Jane Alamina and Dr. P. T. Alamina) for immense support shown.  My wife, children and family members have also stood by given and given all the encouragement I could ever need.  Thank you.  Finally, to all who have said a prayer and have contributed towards my studies or well being, I am grateful.

\chapter*{Copyright statement}
i.	The author of this thesis (including any appendices and/or schedules to this thesis) owns any copyright in it (the “Copyright”) and s/he has given The University of Huddersfield the right to use such copyright for any administrative, promotional, educational and/or teaching purposes.
ii.	Copies of this thesis, either in full or in extracts, may be made only in accordance with the regulations of the University Library. Details of these regulations may be obtained from the Librarian. This page must form part of any such copies made.
iii.	The ownership of any patents, designs, trademarks and any and all other intellectual property rights except for the Copyright (the “Intellectual Property Rights”) and any reproductions of copyright works, for example graphs and tables (“Reproductions”), which may be described in this thesis, may not be owned by the author and may be owned by third parties. Such Intellectual Property Rights and Reproductions cannot and must not be made available for use without the prior written permission of the owner(s) of the relevant Intellectual Property Rights and/or Reproductions 


\tableofcontents

\chapter{Introduction}
\input{chapters/ch01}

\chapter{Low Resource Speech Models, End-to-end models and the scattering network}\label{c02}
\input{chapters/ch02}

\chapter{Recurrent Neural Networks in Speech Recognition}\label{ch3RNN}
\input{chapters/ch03}

\chapter{Deep Scattering network}
\input{chapters/ch04}\label{ch4DSN}

\chapter{Wakirike Language Model}
\input{chapters/ch05}

\chapter{Deep Learning Speech Model}
\input{chapters/ch06}

\chapter{Future study}
\input{chapters/ch07}

\spacing{1.0}
\bibliographystyle{plainnat}

\bibliography{bib}

\end{document}
