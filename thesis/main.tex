\documentclass[12pt,twoside]{report}
\usepackage[bookmarksnumbered=true]{hyperref}
\usepackage{bookmark}

%\hypersetup{
%    colorlinks=true,
%    linkcolor=blue,
%    filecolor=magenta,      
%    urlcolor=cyan,
%    pdftitle={Sharelatex Example},
%    bookmarks=true,
%    pdfpagemode=FullScreen,
%}


\usepackage[natbibapa]{apacite}
\usepackage[T1]{fontenc}
\usepackage{lmodern}
\usepackage{textcomp}
\usepackage[utf8]{inputenc}
\usepackage{stringenc}
\newcommand*{\uni}{}
\DeclareRobustCommand*{\uni}[1]{%
  \begingroup
    \StringEncodingConvert\x{%
      \pdfunescapehex{%
        00%
        \ifnum"#1<"100000 0\fi
        \ifnum"#1<"10000 0\fi
        \ifnum"#1<"1000 0\fi
        \ifnum"#1<"100 0\fi
        \ifnum"#1<"10 0\fi
        #1%
      }%
    }{utf32be}{utf8}%
    \everyeof{\noexpand}%
    \endlinechar=-1 %
  \edef\x{%
    \endgroup
    \scantokens\expandafter{%
      \expandafter\unexpanded\expandafter{\x}%
    }%
  }\x
}

% hyperref support
\usepackage[pdfencoding=auto]{hyperref}
\pdfstringdefDisableCommands{%
  \def\uni#1{\unichar{"#1}}%
}
\usepackage{graphicx}
\graphicspath{ {images/} }
\usepackage[a4paper,width=150mm,top=25mm,bottom=25mm,bindingoffset=6mm]{geometry}
\usepackage{wrapfig}
\usepackage{lscape}
\usepackage{rotating}
\usepackage{epstopdf}
\usepackage{listings}
\usepackage[dvipsnames]{xcolor}

\usepackage{titlesec}
\titlespacing*{\subsubsection}{0pt}{1.1\baselineskip}{\baselineskip}

% package used by \citep and \citet
\usepackage[sort&compress,comma,authoryear]{natbib}
% \usepackage[options ]{algorithm2e}
\usepackage[linesnumbered,lined,boxed,commentsnumbered]{algorithm2e}
\usepackage{url}
\def\UrlBreaks{\do\/\do-}
\usepackage{breakurl}
\usepackage[breaklinks]{hyperref}
\usepackage{setspace}
\usepackage{amsmath}
\usepackage{booktabs}
\usepackage{fancyhdr}
\usepackage[acronym, toc]{glossaries} 

\pagestyle{fancy}
\fancyhead{}
\fancyhead[RO,LE]{Deep Scattering and End-to-End Speech Models towards Low Resource Speech Recognition}
\fancyfoot{}
\fancyfoot[LE,RO]{\thepage}
\fancyfoot[LO,CE]{Chapter \thechapter}
\fancyfoot[CO,RE]{I. J. Alamina}
\renewcommand{\headrulewidth}{0.4pt}
\renewcommand{\footrulewidth}{0.4pt}


\title{
    {Deep Scattering and End-to-End Speech Models towards Low Resource Speech Recognition}\\
    {\includegraphics{university.png}\\
A thesis submitted to the University of Huddersfield in partial fulfilment of the requirements for the degree of Doctor of Philosophy}
}


\author{Iyalla John Alamina}
\date{January 8, 2021}

\begin{document}
\makeglossaries
\input{chapters/glossary.tex}

\maketitle
\DeclareRobustCommand{\startblue}{%
  \leavevmode
  \color{blue}
}
\DeclareRobustCommand{\stopblue}{%
  \normalcolor
}

\spacing{1}

\addcontentsline{toc}{section}{Abstract}
\chapter*{Abstract}
\startblue
Automatic Speech Recognition (ASR) has made major leaps in its advancement largely due to two different machine learning models: Hidden Markov Models (HMMs) and Deep Neural Networks (DNNs).  State-of-the art results have been achieved by combining these two disparate methods to form a hybrid system.  This also requires that various components of the speech recognizer be trained independently based on a probabilistic noisy channel model.  Although this HMM-DNN hybrid ASR method has been successful in recent studies, the independent development of the individual components used in hybrid HMM-DNN models makes ASR development fragile and expensive in terms of time-to-develop the various components and their associated sub-systems.  The resulting trade-off is that ASR systems are difficult to develop and use especially for new applications and languages.

The alternative approach, known as the end-to-end paradigm, makes use of a single deep neural-network architecture used to encapsulate as many as possible sub-components of speech recognition as a single process.  In the so-called end-to-end paradigm, latent variables of sub-components are subsumed by the neural network sub-architectures and the associated parameters.  The end-to-end paradigm gains of a simplified ASR-development process again are traded for higher internal model complexity and computational resources needed to train the end-to-end models. 

This \href{https://docs.google.com/document/d/1ne2ctaxjpOlilMDg88aTtzOdIyP-wI2_ST5mGDvAYMw/edit?usp=sharing}{research} focuses on taking advantage of end-to-end model ASR development gains for new and low-resource languages. Using a specialised light weight convolution-like neural network called the \acrfull{dsn} to replace the input layer of the end-to-end model, our objective was to measure the performance of the end-to-end model using these augmented speech features while checking to see if the lightweight, wavelet-based architecture added any new features that are beneficial for low resource Speech recognition. 

The results showed that it is possible to use this compact strategy as an alternative for speech features required for speech pattern recognition by deploying deep scattering network features with higher dimensional vectors when compared to traditional speech features. With \acrlong{wer}s of 26.8\% and 76.7\% for \acrshort{svcsr} and \acrshort{lvcsr} respective tasks. The \acrshort{asr} system metrics fell few \acrshort{wer} points short of the respective baselines.  In addition, training times tended to be longer when compared to the respective baselines.
\stopblue
\spacing{1.5}


\addcontentsline{toc}{section}{Dedication}
\chapter*{Dedication}
To the praise and glory of our God and of His Christ.

\addcontentsline{toc}{section}{Acknowledgements}
\chapter*{Acknowledgements}
I thank the members supervisory team including Dr David Wilson and Dr Simon Parkinson for the invaluable guidance and keen interest throughout my research.  

I also acknowledge my parents (Prof. Mrs. Jane Alamina and Dr. P. T. Alamina) for immense support shown.  My wife, Ibinabo Alamina, children (Topaz and Jade) and family members have also stood by given and given all the encouragement I could ever need.  Thank you.  Finally, to all who have said a prayer and have contributed towards my studies or well being, I am grateful to you all.

\addcontentsline{toc}{section}{Copyright Statement}
\chapter*{Copyright statement}
\renewcommand{\theenumi}{\roman{enumi}}%
\begin{enumerate}
    \item The author of this thesis (including any appendices and/or schedules to this thesis) owns any copyright in it (the “Copyright”) and s/he has given The University of Huddersfield the right to use such copyright for any administrative, promotional, educational and/or teaching purposes.
    \item Copies of this thesis, either in full or in extracts, may be made only in accordance with the regulations of the University Library. Details of these regulations may be obtained from the Librarian. This page must form part of any such copies made.
    \item The ownership of any patents, designs, trademarks and any and all other intellectual property rights except for the Copyright (the “Intellectual Property Rights”) and any reproductions of copyright works, for example graphs and tables (“Reproductions”), which may be described in this thesis, may not be owned by the author and may be owned by third parties. Such Intellectual Property Rights and Reproductions cannot and must not be made available for use without the prior written permission of the owner(s) of the relevant Intellectual Property Rights and/or Reproductions
\end{enumerate}

\tableofcontents

\addcontentsline{toc}{section}{List of Figures}
\listoffigures
 
\addcontentsline{toc}{section}{List of Tables}
\listoftables
\addcontentsline{toc}{section}{List of Algorithms}
\listofalgorithms

\startblue
\addcontentsline{toc}{section}{Acronyms}

\begin{table}[tp]
\chapter*{List of Abbreviations}
  \label{tab:acronymns}
\begin{tabular}{ll}
\acrshort{am} & \acrlong{am}\\
\acrshort{asr} & \acrlong{asr}\\
\acrshort{bilstm} & \acrlong{bilstm}\\
\acrshort{birnn} & \acrlong{birnn}\\
\acrshort{bleu} & \acrlong{bleu}\\
\acrshort{blstm} & \acrlong{blstm}\\
\acrshort{cfg} & \acrlong{cfg} \\
\acrshort{cmu} & \acrlong{cmu} \\
\acrshort{cmvn} & acrlong{cmvn} \\
\acrshort{cmn} & \acrlong{cmn} \\
\acrshort{cnn} & \acrlong{cnn} \\
\acrshort{ctc} & \acrlong{ctc} \\
\acrshort{cuda} & \acrlong{cuda} \\
\acrshort{cv} & \acrlong{cv} \\
\acrshort{dbn} & \acrlong{dbn} \\
\acrshort{dct} & \acrlong{dct} \\
\acrshort{dnn} & \acrlong{dnn} \\
\acrshort{dnns} & \acrlong{dnns} \\
\acrshort{dsn} & \acrlong{dsn} \\
\acrshort{dtw} & \acrlong{dtw} \\
\acrshort{fsg} & \acrlong{fsg} \\
\acrshort{espnet} & \acrlong{espnet} \\
\acrshort{fsgs} & \acrlong{fsgs} \\
\acrshort{fst} & \acrlong{fst} \\
\acrshort{g2p} & \acrlong{g2p} \\
\acrshort{gan} & \acrlong{gan} \\
\acrshort{gmm} & \acrlong{gmm} \\
\acrshort{gpu} & \acrlong{gpu} \\
\acrshort{gru} & \acrlong{gru} \\
\acrshort{hlda} & \acrlong{hlda} \\
\acrshort{hmm} & \acrlong{hmm} \\
\acrshort{idft} & \acrlong{idft} \\
\acrshort{lda} & \acrlong{lda} \\
\acrshort{llc} & \acrlong{llc} \\
\acrshort{lm} & \acrlong{lm} \\
\acrshort{lpc} & \acrlong{lpc} \\
\acrshort{lstm} & \acrlong{lstm} \\
\acrshort{mfcc} & \acrlong{mfcc} \\
\acrshort{mfsc} & \acrlong{mfsc} \\
\end{tabular}
\end{table}

\clearpage
\begin{table}[tp]
  \label{tab:acronymns2}
\section*{Acronyms contd.}
\begin{tabular}{ll}
\acrshort{mimo} & \acrlong{mimo} \\
\acrshort{miso} & \acrlong{miso} \\
\acrshort{ml} & \acrlong{ml} \\
\acrshort{mllt} & \acrlong{mllt} \\
\acrshort{mlp} & \acrlong{mlp} \\
\acrshort{mlps} & \acrlong{mlps} \\
\acrshort{oov} & \acrlong{oov} \\
\acrshort{plp} & \acrlong{plp} \\
\acrshort{rasta} & \acrlong{rasta} \\
\acrshort{rbm} & \acrlong{rbm} \\
\acrshort{relu} & \acrlong{relu} \\
\acrshort{rnn} & \acrlong{rnn} \\
\acrshort{rnns} & \acrlong{rnns} \\
\acrshort{rnnlm} & \acrlong{rnnlm} \\
\acrshort{sgmm} & \acrlong{sgmm} \\
\acrshort{sgd} & \acrlong{sgd} \\
\acrshort{simo} & \acrlong{simo} \\
\acrshort{siso} & \acrlong{siso} \\
\acrshort{stc} & \acrlong{stc} \\
\acrshort{tts} & \acrlong{tts} \\
\acrshort{vad} & \acrlong{vad} \\
\acrshort{vtln} & \acrlong{vtln} \\
\acrshort{wer} & \acrlong{wer} \\
\acrshort{wfst} & \acrlong{wfst} 
\end{tabular}
\end{table}
\clearpage

\addcontentsline{toc}{section}{List of Symbols}
\begin{table}[tp]
\chapter*{Symbols}
  \label{tab:symbols}
\begin{tabular}{ll}
Symbol & Meaning \\
$\mathbf{O}$ & vector sequence of natural observations \\
$\mathbf{o}_i$ & observation vector at time=i\\
$\mathbf{w}$ & sequence of words recognised \\
$w_i$ & word recognised at time=i\\
$a_{ij}$ & probability between state i and j\\
$b_j$ & probability of output observation\\
$M$ & \acrlong{hmm} \\
$H$ & Entropy of a language \\
$PP$ & Perplexity of a language \\
$\mathbf{x}$ & observation vector in terms of input features \\
$C$ & output machine learning class prediction \\
$\mathbf{W}$ & matrix of neural network weight parameters \\
$E$ & Error margin \\
$\nabla_\mathbf{w}$ & derivative with respect to weights \\
$\sigma$ & neural network non-linear function \\
$\mathbf{h}$ & matrix of hidden state weights \\
$\mathbf{l}$ & sequence of output class labels \\
$\mathbf{y}$ & sequence of output classes \\
$y_{t,p}$ & \acrshort{ctc} output probabilities \\
$\pi$ & \acrshort{ctc} output character sequence \\
$\alpha$ & forward probability per time-step \\
$\beta & backward probability per time-step \\
$\mathcal{L}$ & Cross entropy loss for a sequence of input data\\
$z$ & sequence of output characters \\
$a_k$ & Fourier series coefficient \\
$x$ & continuous signal input \\
$C$ & Continuous wavelet transform \\
$a$ & continuous wavelet scaling factor \\
$b$ & continuous wavelet shifting factor \\
$\phi$ & orthonormal bases (scaling) function \\
$\psi$ & shifting (translation) function \\
$\hat{\psi}$ & mother wavelet \\
$h$ & Haar coefficients \\
$M$ & Mel scale function \\
$\delta_m$ & frequency range \\
$d_t$ & delta-delta \acrshort{mfcc}s \\
$\psi_j$ & Scatter transform wavelet \\
$S_n$ & $n$-th order Scatter transform \\
\end{tabular}
\end{table}
\stopblue

\chapter{\href{https://docs.google.com/document/d/1h8ZEcfEUpjJM6wYkgYYH-ryuiBFYVGSQA-Sf1StQtiY/edit#heading=h.i9tlo6ovvcpr}{Introduction}}\label{ch1_intro}
\input{chapters/ch01}

%\chapter{Low Resource Speech Models, End-to-end models and the scattering
\chapter{\href{https://docs.google.com/document/d/1h8ZEcfEUpjJM6wYkgYYH-ryuiBFYVGSQA-Sf1StQtiY/edit#heading=h.i9tlo6ovvcpr}{Literature Review}}\label{c02}\label{ch2litrev}
\input{chapters/ch02}

%\chapter{Speech processing systems method}
\chapter{Methods, Models and Systems}\label{ch3Method}
\input{chapters/ch03}

%\chapter{Recurrent Neural Networks in Speech Recognition}
\chapter{Background 1: Recurrent Neural Networks in Speech Recognition}\label{ch3RNN}
\input{chapters/ch04}

\chapter{Background 2: Deep Scattering network}\label{ch4DSN}
\input{chapters/ch05}

\chapter{Empirical Analysis 1: Wakirike Language Model}\label{ch6_wlm}
\input{chapters/ch06}

\chapter{Empirical Analysis 2: Deep Recurrent Speech Recognition models}\label{ch6_speech}
\input{chapters/ch07}

\chapter{Conclusion and Future Work}\label{ch8_future}
\input{chapters/ch08}

\spacing{1.0}
\addcontentsline{toc}{chapter}{Appendix I - Haar wavelet}
\chapter*{\appendix}
\input{chapters/ch08a}\label{app_haar}
\addcontentsline{toc}{chapter}{Appendix II - Gabor and Morlet wavelet filters}
\chapter*{\appendix}
\input{chapters/ch08aa}
\addcontentsline{toc}{chapter}{Appendix III - Scatter Transform implementation}
\chapter*{\appendix}
\input{chapters/ch08b}
\addcontentsline{toc}{chapter}{Appendix IV - Sample TensorFlow Client code}
\chapter*{\appendix}
\input{chapters/ch08c}\label{app4_tfcode}
\addcontentsline{toc}{chapter}{Appendix V - Wakirike Phonetic dictionary}
\chapter*{\appendix}
\input{chapters/ch08d}\label{app5_okd}
\bibliographystyle{apacite}
\startblue
\bibliography{bib}
\stopblue
\end{document}
