\documentclass[12pt,twoside]{report}
\usepackage{hyperref}
\usepackage[utf8]{inputenc}
\usepackage{graphicx}
\graphicspath{ {images/} }
\usepackage[a4paper,width=150mm,top=25mm,bottom=25mm,bindingoffset=6mm]{geometry}
\usepackage{wrapfig}
\usepackage{lscape}
\usepackage{rotating}
\usepackage{epstopdf}
\usepackage{listings}
\usepackage[dvipsnames]{xcolor}

% package used by \citep and \citet
\usepackage[sort&compress,comma,authoryear]{natbib}
% \usepackage[options ]{algorithm2e}
\usepackage[linesnumbered,lined,boxed,commentsnumbered]{algorithm2e}
\usepackage{url}
\def\UrlBreaks{\do\/\do-}
\usepackage{breakurl}
\usepackage[breaklinks]{hyperref}
\usepackage{setspace}
\usepackage{amsmath}
\usepackage{booktabs}
\usepackage{fancyhdr}
\usepackage[acronym, toc]{glossaries} 

\pagestyle{fancy}
\fancyhead{}
\fancyhead[RO,LE]{Deep Scattering and End-to-End Speech Models towards Low Resource Speech Recognition}
\fancyfoot{}
\fancyfoot[LE,RO]{\thepage}
\fancyfoot[LO,CE]{Chapter \thechapter}
\fancyfoot[CO,RE]{I. J. Alamina}
\renewcommand{\headrulewidth}{0.4pt}
\renewcommand{\footrulewidth}{0.4pt}


\title{
    {Deep Scattering and End-to-End Speech Models towards Low Resource Speech Recognition}\\
    {\includegraphics{university.png}\\
A thesis submitted to the University of Huddersfield in partial fulfilment of the requirements for the degree of Doctor of Philosophy}
}


\author{Iyalla John Alamina}
\date{January 8, 2021}

\begin{document}
\makeglossaries
\input{chapters/glossary.tex}

\maketitle
\DeclareRobustCommand{\startblue}{%
  \leavevmode
  \color{blue}
}
\DeclareRobustCommand{\stopblue}{%
  \normalcolor
}

\spacing{1}

\addcontentsline{toc}{section}{Abstract}
\chapter*{Abstract}
\startblue
Automatic Speech Recognition (ASR) has made two major leaps in its advancement due to two disparate machine learning models; Hidden Markov Models (HMMs) and Deep Neural Networks (DNNs).  However, combining these two methods to form a hybrid system requires that various components of the speech recognizer are trained independently based on a probabilistic noisy channel model.  Although this HMM-DNN hybrid ASR method has generated state-of-the-art accuracy results, the independent development of the individual components used in hybrid HMM-DNN models makes ASR development fragile and expensive in terms of time-to-develop the various components and their associated sub-systems.  As a result of these trade-offs, ASR systems are difficult to develop and use especially for new applications and languages.

The alternative approach, known as the end-to-end paradigm, makes use of a single deep neural-network architecture used to encapsulate all the sub-components of speech recognition as a single process.  In this end-to-end paradigm, latent variables of sub-components are subsumed by the neural network sub-architectures and the associated parameters.  The end-to-end paradigm gains of a simplified ASR-development process again is traded for higher internal model complexity and more computational resources needed to train the end-to-end models. 

This \href{https://docs.google.com/document/d/1ne2ctaxjpOlilMDg88aTtzOdIyP-wI2_ST5mGDvAYMw/edit?usp=sharing}{research} focuses on taking advantage of end-to-end model ASR development gains for new and low-resource languages. Using a specialised light weight convolution-like neural network called the deep scattering network (DSN) to replace the input layer of the end-to-end model, our objective was to measure the performance of the end-to-end model using these augmented speech features while checking to see if the lightweight, wavelet-based architecture added any new features that are beneficial for low resource Speech recognition. 

The research showed that it is possible to use this compact strategy and improve upon speech features required for speech pattern recognition by deploying deep scattering network features with higher dimensional vectors when compared to traditional speech features.
\stopblue
\spacing{1.5}


\addcontentsline{toc}{section}{Dedication}
\chapter*{Dedication}
To the praise and glory of our God and of His Christ.

\addcontentsline{toc}{section}{Acknowledgements}
\chapter*{Acknowledgements}
I thank the members supervisory team including Dr David Wilson and Dr Simon Parkinson for the invaluable guidance and keen interest throughout my research.  

I also acknowledge my parents (Prof. Mrs. Jane Alamina and Dr. P. T. Alamina) for immense support shown.  My wife, children (Topaz and Jade) and family members have also stood by given and given all the encouragement I could ever need.  Thank you.  Finally, to all who have said a prayer and have contributed towards my studies or well being, I am grateful to you all.

\addcontentsline{toc}{section}{Copyright Statement}
\chapter*{Copyright statement}
\renewcommand{\theenumi}{\roman{enumi}}%
\begin{enumerate}
    \item The author of this thesis (including any appendices and/or schedules to this thesis) owns any copyright in it (the “Copyright”) and s/he has given The University of Huddersfield the right to use such copyright for any administrative, promotional, educational and/or teaching purposes.
    \item Copies of this thesis, either in full or in extracts, may be made only in accordance with the regulations of the University Library. Details of these regulations may be obtained from the Librarian. This page must form part of any such copies made.
    \item The ownership of any patents, designs, trademarks and any and all other intellectual property rights except for the Copyright (the “Intellectual Property Rights”) and any reproductions of copyright works, for example graphs and tables (“Reproductions”), which may be described in this thesis, may not be owned by the author and may be owned by third parties. Such Intellectual Property Rights and Reproductions cannot and must not be made available for use without the prior written permission of the owner(s) of the relevant Intellectual Property Rights and/or Reproductions
\end{enumerate}

\tableofcontents

\addcontentsline{toc}{section}{List of Figures}
\listoffigures
 
\addcontentsline{toc}{section}{List of Tables}
\listoftables
\addcontentsline{toc}{section}{List of Algorithms}
\listofalgorithms
\newpage
\addcontentsline{toc}{section}{Acronyms}
\clearpage

\begin{table}[tp]
\chapter*{Acronyms}
  \label{tab:acronymns}
\begin{tabular}{ll}
\acrshort{am} & \acrlong{am}\\
\acrshort{asr} & \acrlong{asr}\\
\acrshort{bilstm} & \acrlong{bilstm}\\
\acrshort{birnn} & \acrlong{birnn}\\
\acrshort{bleu} & \acrlong{bleu}\\
\acrshort{cfg} & \acrlong{cfg} \\
\acrshort{cmu} & \acrlong{cmu} \\
\acrshort{cmvn} & acrlong{cmvn} \\
\acrshort{cmn} & \acrlong{cmn} \\
\acrshort{cnn} & \acrlong{cnn} \\
\acrshort{ctc} & \acrlong{ctc} \\
\acrshort{dbn} & \acrlong{dbn} \\
\acrshort{dct} & \acrlong{dct} \\
\acrshort{dnn} & \acrlong{dnn} \\
\acrshort{dnns} & \acrlong{dnns} \\
\acrshort{dsn} & \acrlong{dsn} \\
\acrshort{dtw} & \acrlong{dtw} \\
\acrshort{fsg} & \acrlong{fsg} \\
\acrshort{espnet} & \acrlong{espnet} \\
\acrshort{fsgs} & \acrlong{fsgs} \\
\acrshort{fst} & \acrlong{fst} \\
\acrshort{g2p} & \acrlong{g2p} \\
\acrshort{gan} & \acrlong{gan} \\
\acrshort{gmm} & \acrlong{gmm} \\
\acrshort{gpu} & \acrlong{gpu} \\
\acrshort{gru} & \acrlong{gru} \\
\acrshort{hlda} & \acrlong{hlda} \\
\acrshort{hmm} & \acrlong{hmm} \\
\acrshort{idft} & \acrlong{idft} \\
\acrshort{lda} & \acrlong{lda} \\
\acrshort{llc} & \acrlong{llc} \\
\acrshort{lm} & \acrlong{lm} \\
\acrshort{lpc} & \acrlong{lpc} \\
\acrshort{lstm} & \acrlong{lstm} \\
\acrshort{mfcc} & \acrlong{mfcc} \\
\acrshort{mfsc} & \acrlong{mfsc} \\
\acrshort{ml} & \acrlong{ml} \\
\acrshort{mllt} & \acrlong{mllt} \\
\acrshort{mlp} & \acrlong{mlp} \\
\end{tabular}
\end{table}

\clearpage
\begin{table}[tp]
  \label{tab:acronymns2}
\section*{Acronyms contd.}
\begin{tabular}{ll}
  \acrshort{mlps} & \acrlong{mlps} \\
  \acrshort{oov} & \acrlong{oov} \\
    \acrshort{plp} & \acrlong{plp} \\
  \acrshort{rasta} & \acrlong{rasta} \\
  \acrshort{rbm} & \acrlong{rbm} \\
  \acrshort{rnn} & \acrlong{rnn} \\
  \acrshort{rnns} & \acrlong{rnns} \\
  \acrshort{sgmm} & \acrlong{sgmm} \\
  \acrshort{sgd} & \acrlong{sgd} \\
  \acrshort{stc} & \acrlong{stc} \\
  \acrshort{vtln} & \acrlong{vtln} \\
  \acrshort{wer} & \acrlong{wer} 
  \acrshort{wfst} & \acrlong{wfst} 
\end{tabular}
\end{table}
  
\chapter{\href{https://docs.google.com/document/d/1h8ZEcfEUpjJM6wYkgYYH-ryuiBFYVGSQA-Sf1StQtiY/edit#heading=h.i9tlo6ovvcpr}{Introduction}}\label{ch1_intro}
\input{chapters/ch01}

%\chapter{Low Resource Speech Models, End-to-end models and the scattering
\chapter{\href{https://docs.google.com/document/d/1h8ZEcfEUpjJM6wYkgYYH-ryuiBFYVGSQA-Sf1StQtiY/edit#heading=h.i9tlo6ovvcpr}{Literature Review}}\label{c02}\label{ch2litrev}
\input{chapters/ch02}

%\chapter{Speech processing systems method}
\chapter{Methodology}\label{ch3Method}
\input{chapters/ch03}

%\chapter{Recurrent Neural Networks in Speech Recognition}
\chapter{Background 1: Recurrent Neural Networks in Speech Recognition}\label{ch3RNN}
\input{chapters/ch04}

\chapter{Background 2: Deep Scattering network}\label{ch4DSN}
\input{chapters/ch05}

\chapter{Empirical Analysis 1: Wakirike Language Model}\label{ch6_wlm}
\input{chapters/ch06}

\chapter{Empirical Analysis 2: Deep Recurrent Speech Recognition models}\label{ch6_speech}
\input{chapters/ch07}

\chapter{Conclusion and Future Work}\label{ch8_future}
\input{chapters/ch08}
\spacing{1.0}
\addcontentsline{toc}{chapter}{Appendix I - Haar wavelet}
\chapter*{\appendix}
\input{chapters/ch08a}\label{app_haar}
\addcontentsline{toc}{chapter}{Appendix II - Gabor and Morlet wavelet filters}
\chapter*{\appendix}
\input{chapters/ch08aa}
\addcontentsline{toc}{chapter}{Appendix III - Scatter Transform implementation}
\chapter*{\appendix}
\input{chapters/ch08b}
\addcontentsline{toc}{chapter}{Appendix IV - Sample TensorFlow Client code}
\chapter*{\appendix}
\input{chapters/ch08c}\label{app4_tfcode}
\bibliographystyle{chapters/myplainnat}
\startblue
\bibliography{bib}
\stopblue
\end{document}
